{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures of variability \n",
    "\n",
    "Variance or variability in a process is at the root of many defects in a six sigma world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean, median and mode are important summary data metrics. However they don't tell us anything about variability in the data. For example we see an identical median and mean for two samples although the spread or variability is different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_A = [4,4,4,4]\n",
    "Sample_B = [0,8,8,0]\n",
    "\n",
    "mean_A = np.mean(Sample_A)\n",
    "mean_B = np.mean(Sample_B)\n",
    "\n",
    "median_A = np.median(Sample_A)\n",
    "median_B = np.median(Sample_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of sample A is 4.0\n",
      "The mean of sample B is 4.0\n",
      "The median of sample A is 4.0\n",
      "The median of sample B is 4.0\n"
     ]
    }
   ],
   "source": [
    "print('The mean of sample A is', mean_A)\n",
    "print('The mean of sample B is', mean_B)\n",
    "print('The median of sample A is', median_A)\n",
    "print('The median of sample B is', median_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary stats also need to capture variability. Essentially there are four different types of variability:\n",
    "    - 1)Range\n",
    "    - 2)Mean absolute deviation ( including 2a - Mean Deviation)\n",
    "    - 3)Variance\n",
    "    - 4)Standard deviation: the long way\n",
    "    - 5) Standard deviation: the short way\n",
    "    and for completeness\n",
    "    -6) Limitations of measures to different types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1) Range\n",
    "\n",
    "Z = [1,1,1,1,1,1,1,1,1,21]\n",
    "\n",
    "#The range is simply the max - min; the limitation is that only the extreme values are considered.\n",
    "#This makes it sensitive to outliers. As we see in this example the range is 20 when we would expect\n",
    "#it to be closer to zero given the frequency with which 1 appears.\n",
    "range = max(Z) - min(Z)\n",
    "range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the array is 3.0\n"
     ]
    }
   ],
   "source": [
    "#2a) Mean average deviation...... doesn't really work......\n",
    "#..because the average distance will be zero.\n",
    "\n",
    "#To calculated an average deviation, we need a reference point.The mean is often used for this.....\n",
    "mean_array = np.mean(Z)\n",
    "print('The mean of the array is', mean_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example 9 values are below the mean and 1 is above.\n",
    "If we look at the average value we see that they cancel out and = zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-3) * 9) + (21-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The Mean Absolute Deviation\n",
    "\n",
    "To solve the problem of summing to zero, we can take the absolute value of each distance, and then sum up the \n",
    "absolute values. The absolute value (also called modulus) of a number is the positive version of \n",
    "that number, regardless of its sign. Below I calculate the mean absolute distance (deviation). It is larger than 1, but much less than 20 as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_absolute_deviation(array):\n",
    "    reference_point = np.mean(array)\n",
    "    \n",
    "    distances = []\n",
    "    for value in array:\n",
    "        absolute_distance = abs(value - reference_point)\n",
    "        distances.append(absolute_distance)\n",
    "        \n",
    "    return np.mean(distances) # this is sum(distances) / len(distances); we are dividing by n.\n",
    "\n",
    "mad = mean_absolute_deviation(Z)\n",
    "mad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)The Variance\n",
    "\n",
    "An alternative solution is to square each distance and then find the mean of all the squared distances. This measure of variability is sometimes called mean squared distance or mean squared deviation . However, it's more commonly known as variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variance(array):\n",
    "    reference_point = np.mean(array)\n",
    "    \n",
    "    distances = []\n",
    "    for value in array:\n",
    "        squared_distance = (value - reference_point)**2\n",
    "        distances.append(squared_distance)\n",
    "        \n",
    "    return np.mean(distances) # this is basically sum(distances) / len(distances). We are dividing by n.\n",
    "\n",
    "variance_Z = variance(Z)\n",
    "variance_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is higher than expected (i.e greater than 20) which is the result of squaring the difference between the value and the mean. To solve this problem and also reduce the variability value, we can take the square root of variance.\n",
    "\n",
    "4) Standard Deviation\n",
    "\n",
    "The square root of variance is called standard deviation (remember that \"deviation\" is synonymous with \"distance\"). In practice, standard deviation is perhaps the most used measure of variability. It is simply a measure of the of spread in a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def standard_deviation(array):\n",
    "    reference_point = np.mean(array)\n",
    "    \n",
    "    distances = []\n",
    "    for value in array:\n",
    "        squared_distance = (value - reference_point)**2\n",
    "        distances.append(squared_distance)\n",
    "        \n",
    "    variance = sum(distances) / len(distances) # note we are dividing by n\n",
    "    #variance = np.mean(distances)\n",
    "                \n",
    "    return sqrt(variance)\n",
    "\n",
    "standard_deviation_Z = standard_deviation(Z)\n",
    "standard_deviation_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Standard Deviation the short way\n",
    "\n",
    "#Standard deviation formulas can be found in several python packages. However we need consider whether \n",
    "#And let's do this the short way\n",
    "\n",
    "#Option 1: numpy\n",
    "\n",
    "standard_deviation_Z_shortway = np.std(Z)\n",
    "standard_deviation_Z_shortway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of sample A is 0.0\n",
      "The standard deviation of sample B is 4.0\n"
     ]
    }
   ],
   "source": [
    "#Applying option 1 to Samples A and B at the top of the file.\n",
    "\n",
    "standard_deviation_Sample_A = np.std(Sample_A)\n",
    "print('The standard deviation of sample A is', standard_deviation_Sample_A)\n",
    "\n",
    "standard_deviation_Sample_B = np.std(Sample_B)\n",
    "print('The standard deviation of sample B is', standard_deviation_Sample_B)\n",
    "#We are seeing higher SD for sample B as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324555320336759"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Option 2: pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Z = [1,1,1,1,1,1,1,1,1,21]\n",
    "\n",
    "standard_deviation_x_pandas = pd.Series([1,1,1,1,1,1,1,1,1,21]).std()\n",
    "standard_deviation_x_pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using pandas we get 6.32 rather than 6. What is going on?\n",
    "\n",
    "In practice, when calculating standard deviation (and more generally) we are working with samples. Most of the time we're not actually interested in describing the samples. Rather, we want to use the samples to make inferences about their corresponding populations. When we calculate sample standard deviations and compared them against the population standard deviation for a dataset (not done here) we notice that most sample standard deviations are clustered below the population standard deviation. Put simply this suggests that sample standard deviation usually underestimates the population standard deviation. \n",
    "\n",
    "To correct the underestimation problem, we can try to slightly modify the sample standard deviation formula to return higher values by dividing by to n-1 rather than n. This is called the Bessel correction which is the use of n âˆ’ 1 instead of n in the formula for the sample variance and sample standard deviation, where n is the number of observations in a sample. This method corrects the bias in the estimation of the population variance.\n",
    "\n",
    "Using n-1 is also the default in scipy (option 3 below). \n",
    "Put simply this means that pandas and scipy make the Bessel correction as a default; numpy does not.\n",
    "\n",
    "It is important to remember that excel uses n-1 (i.e the Bessel correction) as a default.\n",
    "\n",
    "Remember when working with population we continue to use N (rather than n-1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.324555320336759"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Option 3: Scipy\n",
    "\n",
    "import scipy\n",
    "\n",
    "scipy.stats.tstd(Z, limits=None, inclusive=(True, True), axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6784150009988332"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check Sig sigma book (pg65-68)\n",
    "\n",
    "list = [2,3.5,2.3,2,2.5,3.1,2.2,3.2,4]\n",
    "np.std(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7195677714974301"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([2,3.5,2.3,2,2.5,3.1,2.2,3.2,4]).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! Excel default setting is n-1 (i.e including bessel correction) - we divide by a small denominator and get a bigger std."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Limitations\n",
    "\n",
    "The variability metrics discussed here are useful for distributions whose values are measured on an interval or ratio scale. Measuring variability for ordinal and nominal data is much harder because we can't quantify the differences between values. For this reason, little is written in the literature about measuring variability for ordinal and nominal data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
